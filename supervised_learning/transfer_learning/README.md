# Transfer Learning - Entra√Ænement de mod√®les CIFAR-10

Ce projet impl√©mente un syst√®me d'entra√Ænement de mod√®les de classification d'images utilisant le transfer learning sur le dataset CIFAR-10.

## üìã Pr√©requis

### Installation automatique (recommand√©e)

Le script `run.sh` installe automatiquement toutes les d√©pendances :

**macOS/Linux :**
```bash
chmod +x run.sh  # Une seule fois
./run.sh train   # Installation automatique + entra√Ænement
```

### Installation manuelle

Si vous pr√©f√©rez installer manuellement :

**D√©pendances de base :**
```bash
pip install -r requirements.txt
```

**Optimisations macOS Apple Silicon (M1/M2) :**
```bash
pip install -r requirements-macos.txt
```

### Versions requises
- Python 3.8+
- TensorFlow 2.8+ (+ tensorflow-metal sur macOS Apple Silicon)
- Matplotlib 3.5+
- NumPy 1.21+

## üöÄ Utilisation

### M√©thode recommand√©e : Script interactif

**macOS/Linux :**
```bash
./run.sh
```

Le script vous proposera 3 options :

#### **Option 1 : Entra√Ænement (0-transfer.py)**
- üéØ **Objectif** : Entra√Æner un nouveau mod√®le de classification CIFAR-10
- ‚è±Ô∏è **Dur√©e** : ~14 minutes (selon votre mat√©riel)
- üíæ **Sortie** : Cr√©e `cifar10.h5` + graphiques dans `img/`
- üîß **Quand l'utiliser** : Premi√®re fois ou pour r√©entra√Æner avec de nouveaux param√®tres

#### **Option 2 : √âvaluation (0-main.py)**
- üéØ **Objectif** : Tester les performances d'un mod√®le d√©j√† entra√Æn√©
- ‚è±Ô∏è **Dur√©e** : 30 secondes - 2 minutes
- üìä **Sortie** : Affiche l'accuracy finale sur l'ensemble de test complet
- üîß **Quand l'utiliser** : Apr√®s avoir entra√Æn√© un mod√®le (option 1)
- ‚ö†Ô∏è **Pr√©requis** : Fichier `cifar10.h5` doit exister

#### **Option 3 : Installation des d√©pendances**
- üéØ **Objectif** : Installer/mettre √† jour TensorFlow et les d√©pendances
- üí° **Auto-d√©tection** : Installe `tensorflow-metal` si macOS Apple Silicon
- üîß **Quand l'utiliser** : 
  - Premi√®re utilisation du projet
  - Probl√®mes d'import Python
  - Apr√®s mise √† jour de Python

### M√©thode alternative : Ex√©cution directe

Si vous pr√©f√©rez lancer les scripts manuellement :

**Entra√Ænement :**
```bash
python3 0-transfer.py
```

**√âvaluation :**
```bash
python3 0-main.py
```

### Processus d'entra√Ænement complet

1. **Chargement** : Dataset CIFAR-10 (50,000 images d'entra√Ænement)
2. **Pr√©traitement** : Redimensionnement 32x32 ‚Üí 224x224 + normalisation
3. **Mod√®le** : Transfer learning avec EfficientNetV2B1 pr√©-entra√Æn√©
4. **Entra√Ænement** : Fine-tuning avec early stopping
5. **Sauvegarde** : Meilleur mod√®le dans `cifar10.h5`
6. **Graphiques** : Courbes d'apprentissage dans `img/training_plots.png`

## ‚öôÔ∏è Configuration

### Param√®tres actuels (optimis√©s pour de bonnes performances)

Les variables dans `0-transfer.py` sont actuellement configur√©es pour obtenir **~91% de validation accuracy** :

```python
LEARNING_RATE = 0.001         # Taux d'apprentissage optimal pour convergence stable
BATCH_SIZE = 128              # Taille des mini-batchs recommand√©e
EPOCHS = 5                    # Suffisant avec early stopping
DROPOUT_RATE = 0.3            # Dropout mod√©r√©
DENSE_UNITS = 256             # Unit√©s dans la couche dense
TRAIN_SAMPLES = 50000         # Utiliser tout le train set
VAL_SAMPLES = 10000           # Utiliser tout le test set
MODEL_NAME = 'EfficientNetV2B1'  # Mod√®le √† utiliser
PATIENCE = 5
TRAINABLE = True              # Boolean d'activation du d√©g√®le des couches
NB_UNFREEZE_LAYERS = 15       # Nombre de couches √† d√©congeler (si TRAINABLE == True)
PLOT = True                   # Boolean pour afficher les graphs √† la fin de l'entrainement
```


### Mod√®les disponibles

Le code supporte plusieurs architectures pr√©-entra√Æn√©es :
- `EfficientNetV2B1` (recommand√©)
- `MobileNetV2`
- `ResNet50`

## üìä Sortie

Apr√®s l'entra√Ænement, vous obtiendrez :

### Fichiers g√©n√©r√©s
- `cifar10.h5` : Le meilleur mod√®le sauvegard√©
- `img/training_plots.png` : Graphiques de suivi de l'entra√Ænement

### Graphiques de suivi
- **Pr√©cision** : √âvolution de l'accuracy sur train/validation
- **Perte** : √âvolution de la loss sur train/validation  
- **Pr√©cision en %** : Version en pourcentage de l'accuracy
- **D√©tection d'overfitting** : Diff√©rence train-validation

### R√©sum√© d'entra√Ænement
Le script affiche automatiquement :
- Configuration utilis√©e
- R√©sultats finaux (accuracy, loss)
- Diagnostic d'overfitting/underfitting
- Temps d'ex√©cution d√©taill√©

## üìÅ Structure des fichiers

```
transfer_learning/
‚îú‚îÄ‚îÄ 0-transfer.py           # üéØ Option 1: Script d'entra√Ænement
‚îú‚îÄ‚îÄ 0-main.py              # üìä Option 2: Script d'√©valuation
‚îú‚îÄ‚îÄ plot.py                # Affiche des plots avec matplot si la variable PLOT est sur True (pour 0-transfer.py)
‚îú‚îÄ‚îÄ run.sh                 # üöÄ Script interactif (3 options)
‚îú‚îÄ‚îÄ requirements.txt       # üì¶ D√©pendances de base
‚îú‚îÄ‚îÄ requirements-macos.txt # üçé Optimisations macOS (tensorflow-metal)
‚îú‚îÄ‚îÄ README.md              # üìñ Ce fichier
‚îú‚îÄ‚îÄ cifar10.h5             # ü§ñ Mod√®le sauvegard√© (g√©n√©r√© par option 1)
‚îî‚îÄ‚îÄ img/                   # üìà Graphiques (cr√©√© automatiquement)
    ‚îî‚îÄ‚îÄ training_plots.png # üìä Courbes d'apprentissage
```

### Menu interactif du script

Quand vous lancez `./run.sh`, vous avez ces choix :

```
Quel script voulez-vous lancer ?
1) 0-transfer.py (Entra√Ænement)   ‚Üê Cr√©er/entra√Æner un mod√®le
2) 0-main.py (√âvaluation)         ‚Üê Tester un mod√®le existant
3) Installer les d√©pendances      ‚Üê Setup/r√©paration environnement
```

## üîß Fonctionnalit√©s

### Transfer Learning
- Utilise des mod√®les pr√©-entra√Æn√©s sur ImageNet
- Support du fine-tuning (d√©gel de couches)
- Preprocessing automatique selon le mod√®le choisi

### Monitoring
- Early stopping bas√© sur la validation accuracy
- Sauvegarde du meilleur mod√®le automatique
- Graphiques d√©taill√©s de l'entra√Ænement

### Optimisations
- Redimensionnement automatique 32x32 ‚Üí 224x224
- Augmentation de donn√©es int√©gr√©e
- Gestion m√©moire optimis√©e

## üí° Conseils d'utilisation

### Pour √©viter l'overfitting :
- Augmentez `DROPOUT_RATE`
- Diminuez `EPOCHS`
- R√©duisez `TRAIN_SAMPLES`

### Pour am√©liorer les performances :
- Utilisez `EfficientNetV2B1` ou `EfficientNetB0`
- Activez le fine-tuning avec `TRAINABLE = True`
- Augmentez `NB_UNFREEZE_LAYERS` graduellement

### Pour un entra√Ænement plus rapide :
- Utilisez `MobileNetV2`
- R√©duisez `TRAIN_SAMPLES` et `VAL_SAMPLES`
- Augmentez `BATCH_SIZE` si votre GPU le permet

## üìà R√©sultats attendus

### Configuration de test optimis√©e (variables actuelles dans 0-transfer.py)

Les param√®tres actuels ont √©t√© optimis√©s et test√©s avec les r√©sultats suivants :

```python
LEARNING_RATE = 0.001      # Taux d'apprentissage r√©duit pour stabilit√©
EPOCHS = 5                 # Plus d'√©poques pour convergence
DROPOUT_RATE = 0.3         # Dropout mod√©r√©
NB_UNFREEZE_LAYERS = 15    # Fine-tuning plus agressif
```


### Performances obtenues (MacBook M1 Pro 16GB)

**Configuration de test :**
- üñ•Ô∏è **Mat√©riel** : MacBook M1 Pro avec 16GB RAM
- ‚ö° **Acc√©l√©ration** : tensorflow-metal (GPU Apple Silicon)
- üéØ **Mod√®le** : EfficientNetV2B1 avec fine-tuning (40 couches d√©gel√©es)

**Meilleur r√©sultat exp√©rimental :**
```
============================================================
üìä R√âSUM√â DE L'ENTRA√éNEMENT
============================================================
üîß Configuration:
  ‚Ä¢ Mod√®le: EfficientNetV2B1
  ‚Ä¢ Learning Rate: 0.001
  ‚Ä¢ Batch Size: 128
  ‚Ä¢ Dropout: 0.3
  ‚Ä¢ Dense Units: 256
  ‚Ä¢ Unfreezed layers: 40

üìà R√©sultats finaux:
  ‚Ä¢ Training Accuracy: 88.75%
  ‚Ä¢ Validation Accuracy: 93.79%
  ‚Ä¢ Meilleure val accuracy: 93.91%
  ‚Ä¢ Training Loss: 0.3257
  ‚Ä¢ Validation Loss: 0.1859

üîç Diagnostic:
  ‚úÖ Bon √©quilibre! Diff√©rence: -5.04%

‚è±Ô∏è  Temps d'ex√©cution:
  ‚Ä¢ Temps total: 867.73s (14.46min)
  ‚Ä¢ Temps d'entra√Ænement: 864.73s (14.41min)
  ‚Ä¢ Temps par √©poque: 172.95s
============================================================
```
**√âvaluation :**
```
313/313 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 36s 100ms/step - accuracy: 0.9391 - loss: 0.1830
```

Vos r√©sultats peuvent varier selon votre configuration :

### Facteurs influen√ßant les performances

- **üî• RAM disponible** : 8GB minimum, 16GB recommand√©
- **‚ö° Type de processeur** : Apple Silicon > GPU NVIDIA > CPU moderne > CPU ancien
- **üå°Ô∏è Thermique** : Les performances peuvent diminuer si surchauffe
- **üíæ Stockage** : SSD plus rapide que HDD pour le chargement des donn√©es

## üñ•Ô∏è Optimisations par plateforme

### macOS Apple Silicon (M1/M2/M3)
- **Acc√©l√©ration GPU** : Installation automatique de `tensorflow-metal`
- **Performance** : ~2-3x plus rapide qu'en mode CPU uniquement
- **D√©tection automatique** : Le script d√©tecte l'architecture `arm64`

### macOS Intel
- **TensorFlow standard** : Pas d'optimisations GPU sp√©ciales
- **Compatibilit√©** : Fonctionne avec TensorFlow classique

### Linux
- **TensorFlow standard** : Compatible avec CUDA si disponible
- **Flexibilit√©** : Possibilit√© d'ajouter tensorflow-gpu manuellement

### Windows
- **PowerShell Core** : Compatible avec PowerShell 5.1+ et 7+
- **TensorFlow standard** : Support CUDA possible

## ‚ö†Ô∏è Notes importantes

### Configuration et compatibilit√©
- Le code g√®re automatiquement les certificats SSL pour le t√©l√©chargement des mod√®les
- Les images CIFAR-10 sont automatiquement redimensionn√©es pour correspondre aux mod√®les pr√©-entra√Æn√©s
- Le preprocessing est sp√©cifique √† chaque architecture de mod√®le
- **macOS M1/M2** : tensorflow-metal peut prendre 1-2 minutes pour s'installer au premier lancement

### Performance et r√©sultats
- **R√©sultats de r√©f√©rence** obtenus avec MacBook M1 Pro 16GB + tensorflow-metal
- **Variabilit√©** : Vos r√©sultats peuvent diff√©rer selon votre mat√©riel (¬±3-5% d'accuracy)
- **Reproductibilit√©** : Les r√©sultats peuvent l√©g√®rement varier entre les ex√©cutions (nature stochastique de l'entra√Ænement)
- **Recommandation** : Si vos r√©sultats sont < 85%, essayez l'option 3 du menu pour r√©installer tensorflow-metal

### D√©pannage courant
- **Erreur de m√©moire** : R√©duisez `BATCH_SIZE` ou `TRAIN_SAMPLES`
- **Lenteur excessive** : V√©rifiez que tensorflow-metal est install√© (macOS M1/M2)
- **Accuracy faible** : Augmentez `EPOCHS` ou `NB_UNFREEZE_LAYERS`
