import matplotlib.pyplot as plt
from config import LEARNING_RATE, BATCH_SIZE, EPOCHS, DROPOUT_RATE, DENSE_UNITS, MODEL_NAME, PATIENCE, TRAINABLE, NB_UNFREEZE_LAYERS

def plot_training_history(history, save_path='img/training_plots.png'):
    """Cr√©e des graphiques pour visualiser l'entra√Ænement."""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle(f'R√©sultats d\'entra√Ænement - {MODEL_NAME}', fontsize=16)

    # Accuracy
    axes[0, 0].plot(history.history['accuracy'], 'b-', label='Training Accuracy', linewidth=2)
    axes[0, 0].plot(history.history['val_accuracy'], 'r-', label='Validation Accuracy', linewidth=2)
    axes[0, 0].set_title('Pr√©cision du mod√®le')
    axes[0, 0].set_xlabel('√âpoque')
    axes[0, 0].set_ylabel('Pr√©cision')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)

    # Loss
    axes[0, 1].plot(history.history['loss'], 'b-', label='Training Loss', linewidth=2)
    axes[0, 1].plot(history.history['val_loss'], 'r-', label='Validation Loss', linewidth=2)
    axes[0, 1].set_title('Perte du mod√®le')
    axes[0, 1].set_xlabel('√âpoque')
    axes[0, 1].set_ylabel('Perte')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)

    # Accuracy en pourcentage
    axes[1, 0].plot([acc*100 for acc in history.history['accuracy']], 'b-', label='Training %', linewidth=2)
    axes[1, 0].plot([acc*100 for acc in history.history['val_accuracy']], 'r-', label='Validation %', linewidth=2)
    axes[1, 0].set_title('Pr√©cision en pourcentage')
    axes[1, 0].set_xlabel('√âpoque')
    axes[1, 0].set_ylabel('Pr√©cision (%)')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)

    # Diff√©rence entre train et val (overfitting detection)
    diff_acc = [t-v for t, v in zip(history.history['accuracy'], history.history['val_accuracy'])]
    axes[1, 1].plot(diff_acc, 'g-', label='Train - Val Accuracy', linewidth=2)
    axes[1, 1].axhline(y=0, color='k', linestyle='--', alpha=0.5)
    axes[1, 1].set_title('D√©tection d\'overfitting')
    axes[1, 1].set_xlabel('√âpoque')
    axes[1, 1].set_ylabel('Diff√©rence pr√©cision')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()
    print(f"üìä Graphiques sauvegard√©s dans : {save_path}")

def print_training_summary(history, training_time, total_time):
    """Affiche un r√©sum√© d√©taill√© de l'entra√Ænement."""
    final_train_acc = history.history['accuracy'][-1] * 100
    final_val_acc = history.history['val_accuracy'][-1] * 100
    best_val_acc = max(history.history['val_accuracy']) * 100
    final_train_loss = history.history['loss'][-1]
    final_val_loss = history.history['val_loss'][-1]

    print("\n" + "="*60)
    print("üìä R√âSUM√â DE L'ENTRA√éNEMENT")
    print("="*60)
    print(f"üîß Configuration:")
    print(f"   ‚Ä¢ Mod√®le: {MODEL_NAME}")
    print(f"   ‚Ä¢ Learning Rate: {LEARNING_RATE}")
    print(f"   ‚Ä¢ Batch Size: {BATCH_SIZE}")
    print(f"   ‚Ä¢ Epochs: {EPOCHS}")
    print(f"   ‚Ä¢ Dropout: {DROPOUT_RATE}")
    print(f"   ‚Ä¢ Dense Units: {DENSE_UNITS}")
    if TRAINABLE == True:
        print(f"   ‚Ä¢ Unfreezed layers: {NB_UNFREEZE_LAYERS}")
    print(f"   ‚Ä¢ Patience: {PATIENCE}")

    print(f"\nüìà R√©sultats finaux:")
    print(f"   ‚Ä¢ Training Accuracy: {final_train_acc:.2f}%")
    print(f"   ‚Ä¢ Validation Accuracy: {final_val_acc:.2f}%")
    print(f"   ‚Ä¢ Meilleure val accuracy: {best_val_acc:.2f}%")
    print(f"   ‚Ä¢ Training Loss: {final_train_loss:.4f}")
    print(f"   ‚Ä¢ Validation Loss: {final_val_loss:.4f}")

    overfitting = final_train_acc - final_val_acc
    print(f"\nüîç Diagnostic:")
    if overfitting > 5:
        print(f"Surapprentissage d√©tect√© ! ({overfitting})")
    elif overfitting < -5:
        print(f"Sous-apprentissage d√©tect√© ! ({overfitting})")
    else:
        print(f"Bon √©quilibre ! ({overfitting})")

    print(f"\n‚è±Ô∏è  Temps d'ex√©cution:")
    print(f"   ‚Ä¢ Temps total: {total_time:.2f}s ({total_time/60:.2f}min)")
    print(f"   ‚Ä¢ Temps d'entra√Ænement: {training_time:.2f}s ({training_time/60:.2f}min)")
    print(f"   ‚Ä¢ Temps par √©poque: {training_time/len(history.history['loss']):.2f}s")
    print("="*60)
